{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": "# define Upsample block "
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "2.0.0-alpha0\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "print(tf.__version__)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "class UpSampleLayer(tf.keras.Model):\n",
        "    def __init__(self, filter, **kwargs):\n",
        "        super(UpSampleLayer, self).__init__()\n",
        "        # set default conv attributes\n",
        "        self.conv_dict \u003d {}\n",
        "        self.conv_dict[\u0027filter\u0027] \u003d filter\n",
        "        self.conv_dict[\u0027kernel\u0027 ] \u003d 4\n",
        "        self.conv_dict[\u0027strides\u0027] \u003d 2\n",
        "        self.conv_dict[\u0027padding\u0027] \u003d \u0027same\u0027\n",
        "        self.conv_dict[\u0027activation\u0027] \u003d \u0027relu\u0027\n",
        "        \n",
        "        for key, value in kwargs.items():\n",
        "            self.conv_dict[key] \u003d value\n",
        "\n",
        "        self.conv \u003d tf.keras.layers.Conv2DTranspose(\n",
        "            self.conv_dict[\u0027filter\u0027],\n",
        "            kernel_size\u003dself.conv_dict[\u0027kernel\u0027], \n",
        "            strides\u003dself.conv_dict[\u0027strides\u0027],\n",
        "            padding\u003dself.conv_dict[\u0027padding\u0027], \n",
        "            activation\u003dself.conv_dict[\u0027activation\u0027])\n",
        "\n",
        "    def call(self, x):\n",
        "        #this for debug\n",
        "        #print(self.conv_dict)\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "class UpSampleBlock(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(UpSampleBlock, self).__init__()\n",
        "        self.cv1 \u003d UpSampleLayer(128, kernel\u003d4, strides\u003d2, padding\u003d\u0027same\u0027, activation\u003d\u0027relu\u0027)\n",
        "        self.cv2 \u003d UpSampleLayer(64, kernel\u003d4, strides\u003d2, padding\u003d\u0027same\u0027, activation\u003d\u0027relu\u0027)\n",
        "        self.cv3 \u003d UpSampleLayer(3, kernel\u003d7, strides\u003d1, padding\u003d\u0027same\u0027, activation\u003d\u0027relu\u0027)\n",
        "\n",
        "    def call(self, x):\n",
        "        x \u003d self.cv1(x)\n",
        "        x \u003d self.cv2(x)\n",
        "        x \u003d self.cv3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Test upsample block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "chekck input must be 4 dim :(2, 128, 128, 3)\n",
            "x.shape:(2, 512, 512, 3)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": [
        "ub \u003d UpSampleBlock()\n",
        "data_size\u003d10\n",
        "img_width \u003d 128\n",
        "img_height\u003d128\n",
        "img_channel \u003d 3\n",
        "\n",
        "x_data \u003d np.random.normal(size \u003d [data_size, img_width, img_height, img_channel])\n",
        "hair_color \u003d np.random.uniform(low\u003d0, high\u003d3, size\u003d[data_size])\n",
        "gender \u003d np.random.uniform(low\u003d0, high \u003d 1, size\u003d[data_size])\n",
        "old \u003d np.random.uniform(low\u003d0, high\u003d1, size\u003d[data_size])\n",
        "\n",
        "\n",
        "train_dataset \u003d tf.data.Dataset.from_tensor_slices(x_data)\n",
        "train_dataset \u003d train_dataset.shuffle(2).batch(2)\n",
        "\n",
        "for img in train_dataset.take(1) :\n",
        "    print(f\u0027chekck input must be 4 dim :{img.shape}\u0027)\n",
        "    \n",
        "    x \u003d ub(img)\n",
        "    print(f\u0027x.shape:{x.shape}\u0027)\n",
        "#     l_adv \u003d np.log(d_src(img))\n",
        "    \n",
        "# x \u003d ub(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# define Down-sample block "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "class DownSampleLayer(tf.keras.Model):\n",
        "    def __init__(self,filter, **kwargs):\n",
        "        super(DownSampleLayer, self).__init__()\n",
        "        # set default conv attributes\n",
        "        self.conv_dict \u003d {}\n",
        "        self.conv_dict[\u0027filter\u0027] \u003d filter\n",
        "        self.conv_dict[\u0027kernel\u0027 ] \u003d 4\n",
        "        self.conv_dict[\u0027strides\u0027] \u003d 2\n",
        "        self.conv_dict[\u0027padding\u0027] \u003d \u0027same\u0027\n",
        "        self.conv_dict[\u0027activation\u0027] \u003d \u0027relu\u0027\n",
        "        \n",
        "        for key, value in kwargs.items():\n",
        "            self.conv_dict[key] \u003d value\n",
        "            \n",
        "        self.conv \u003d tf.keras.layers.Conv2D(\n",
        "            self.conv_dict[\u0027filter\u0027],\n",
        "            kernel_size\u003dself.conv_dict[\u0027kernel\u0027], \n",
        "            strides\u003dself.conv_dict[\u0027strides\u0027],\n",
        "            padding\u003dself.conv_dict[\u0027padding\u0027], \n",
        "            activation\u003dself.conv_dict[\u0027activation\u0027])\n",
        "        \n",
        "    def call(self, x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "class DownSampleBlock(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(DownSampleBlock, self).__init__()\n",
        "        self.cv1 \u003d DownSampleLayer(64, kernel\u003d7, strides \u003d 1)\n",
        "        self.cv2 \u003d DownSampleLayer(128, kernel\u003d4, strides \u003d 2)\n",
        "        self.cv3 \u003d DownSampleLayer(256, kernel\u003d4, strides \u003d 2)\n",
        "        \n",
        "    def call(self,x):\n",
        "        x \u003d self.cv1(x)\n",
        "        x \u003d self.cv2(x)\n",
        "        x \u003d self.cv3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Test downsample block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chekck input must be 4 dim :(2, 128, 128, 3)\n",
            "x.shape:(2, 32, 32, 256)\n"
          ]
        }
      ],
      "source": [
        "db \u003d DownSampleBlock()\n",
        "\n",
        "for img in train_dataset.take(1):\n",
        "    print(f\u0027chekck input must be 4 dim :{img.shape}\u0027)\n",
        "    x \u003d db(img)\n",
        "    print(f\u0027x.shape:{x.shape}\u0027)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "class HiddenBlock(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(HiddenBlock, self).__init__()\n",
        "        self.hidden1 \u003d DownSampleLayer(128, kernel\u003d4, strides\u003d2, padding\u003d\u0027valid\u0027, activation\u003d\u0027LeakyReLU\u0027)\n",
        "        self.hidden2 \u003d DownSampleLayer(256, kernel\u003d4, strides\u003d2, padding\u003d\u0027valid\u0027, activation\u003d\u0027LeakyReLU\u0027)\n",
        "        self.hidden3 \u003d DownSampleLayer(512, kernel\u003d4, strides\u003d2, padding\u003d\u0027valid\u0027, activation\u003d\u0027LeakyReLU\u0027)\n",
        "        self.hidden4 \u003d DownSampleLayer(1024, kernel\u003d4, strides\u003d2, padding\u003d\u0027valid\u0027, activation\u003d\u0027LeakyReLU\u0027)\n",
        "        self.hidden5 \u003d DownSampleLayer(2048, kernel\u003d4, strides\u003d2, padding\u003d\u0027valid\u0027, activation\u003d\u0027LeakyReLU\u0027)\n",
        "\n",
        "    def call(self, input):\n",
        "        output \u003d self.hidden1(input)\n",
        "        output \u003d self.hidden2(output)\n",
        "        output \u003d self.hidden3(output)\n",
        "        output \u003d self.hidden4(output)\n",
        "        output \u003d self.hidden5(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "class InstanceNormalization(tf.keras.layers.Layer):\n",
        "    \"\"\"InstanceNormalization for only 4-rank Tensor (image data)\n",
        "    \"\"\"\n",
        "    def __init__(self, epsilon\u003d1e-5):\n",
        "        super(InstanceNormalization, self).__init__()\n",
        "        self.epsilon \u003d epsilon\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        shape \u003d tf.TensorShape(input_shape)\n",
        "        param_shape \u003d shape[-1]\n",
        "        # Create a trainable weight variable for this layer.\n",
        "        self.gamma \u003d self.add_weight(name\u003d\u0027gamma\u0027,\n",
        "                                     shape\u003dparam_shape,\n",
        "                                     initializer\u003d\u0027ones\u0027,\n",
        "                                     trainable\u003dTrue)\n",
        "        self.beta \u003d self.add_weight(name\u003d\u0027beta\u0027,\n",
        "                                    shape\u003dparam_shape,\n",
        "                                    initializer\u003d\u0027zeros\u0027,\n",
        "                                    trainable\u003dTrue)\n",
        "        # Make sure to call the `build` method at the end\n",
        "        super(InstanceNormalization, self).build(input_shape)\n",
        "        \n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        # Compute the axes along which to reduce the mean / variance\n",
        "        input_shape \u003d inputs.get_shape()\n",
        "        reduction_axes \u003d [1, 2] # only shape index\n",
        "        mean, variance \u003d tf.nn.moments(inputs, reduction_axes, keep_dims\u003dTrue)\n",
        "        normalized \u003d (inputs - mean) / tf.sqrt(variance + self.epsilon)\n",
        "        return self.gamma * normalized + self.beta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(tf.keras.Model):\n",
        "    def __init__(self, filter, kernel ):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.layer1 \u003d DownSampleLayer(filter, kernel\u003dkernel, activation\u003d\u0027relu\u0027)\n",
        "        self.bn1 \u003d InstanceNormalization()\n",
        "        self.layer2 \u003d DownSampleLayer(filter, kernel\u003dkernel, activation\u003d\u0027none\u0027)\n",
        "        self.bn2 \u003d InstanceNormalization()\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, input):\n",
        "        output \u003d self.layer1(input)\n",
        "        output \u003d self.bn1(output)\n",
        "        output \u003d self.layer2(output)\n",
        "        output \u003d self.bn2(output)\n",
        "        return ReLU(input+output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "class DiscSrc(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(DiscSrc, self).__init__()\n",
        "        self.cv1 \u003d DownSampleLayer(64, kernel\u003d4, strides\u003d2, padding\u003d\u0027valid\u0027, activation\u003d\u0027LeakyReLU\u0027)\n",
        "        self.hidden \u003d HiddenBlock()\n",
        "        self.fc \u003d DownSampleLayer(1, kernel\u003d3, strides\u003d1, padding\u003d\u0027valid\u0027)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, input):\n",
        "        output \u003d self.cv1(input)\n",
        "        output \u003d self.hidden(output)\n",
        "        output \u003d self.fc(output)\n",
        "        return output "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": [
        "class DiscCls(tf.keras.Model):\n",
        "    def __init__(self, unit, kernel):\n",
        "        super(DiscCls, self).__init__()\n",
        "        self.cv1 \u003d DownSampleLayer(64, kernel\u003d4, strides\u003d2, padding\u003d\u0027valid\u0027, activation\u003d\u0027LeakyReLU\u0027)\n",
        "        self.hidden \u003d HiddenBlock()\n",
        "        self.fc \u003d DownSampleLayer(unit, kernel\u003dkernel, strides\u003d1, padding\u003d\u0027same\u0027)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, input):\n",
        "        output \u003d self.cv1(input)\n",
        "        output \u003d self.hidden(output)\n",
        "        output \u003d self.fc(output)\n",
        "        return output "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "class Generator(tf.keras.Model):\n    def __init__(self, unit, kernel):\n        super(Generator, self).__init__()\n        self.ds1 \u003d DownSampleLayer(64, kernel\u003d7, strides\u003d1, padding\u003d\u0027valid\u0027, activation\u003d\u0027ReLU\u0027)\n        self.ds2 \u003d DownSampleLayer(128,kernel\u003d4, strides\u003d2, padding\u003d\u0027valid\u0027, activation\u003d\u0027ReLU\u0027)\n        self.ds3 \u003d DownSampleLayer(256,kernel\u003d4, strides\u003d2, padding\u003d\u0027valid\u0027, activation\u003d\u0027ReLU\u0027)\n        self.hidden1 \u003d HiddenBlock()\n        self.us1 \u003d UpSampleBlock(128, kernel\u003d4, strides\u003d2, padding\u003d\u0027valid\u0027, activation\u003d\u0027ReLU\u0027)\n        self.us2 \u003d UpSampleBlock(128, kernel\u003d4, strides\u003d2, padding\u003d\u0027valid\u0027, activation\u003d\u0027ReLU\u0027)\n        self.conv \u003d DownSampleLayer(3, kernel\u003d7, strides\u003d1, padding\u003d\u0027same\u0027, activation\u003d\u0027tanh\u0027)\n        \n    @tf.function       \n    def call(self, input):\n        output \u003d self.ds1(input)\n        output \u003d self.ds2(output)\n        output \u003d self.ds3(output)\n        output \u003d self.hidden1(output)\n        output \u003d self.us1(output)\n        output \u003d self.us2(output)\n        output \u003d self.conv(output)\n        return output \n    "
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "test\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "print(\u0027test\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\nlambda_rec \u003d 10\nlambda_cls \u003d 1 \n\n\ndef adverserial_loss(logits, real\u003dTrue):\n  if real \u003d\u003d True:\n    loss \u003d tf.losses.sigmoid_cross_entropy(multi_class_labels \u003d tf.ones_like(logits),logits \u003d logits)\n  else:\n    loss \u003d tf.losses.sigmoid_cross_entropy(multi_class_labels \u003d tf.zeros_like(logits),logits \u003d logits)\n  return loss\n\ndef reconstruction_loss(image,rec_image):\n  return lambda_rec * np.abs(tf.reduce_mean(image  - rec_image))\n\ndef domain_cls_loss(domain, logits):\n  return lambda_cls * tf.losses.sigmoid_cross_entropy(multi_class_labels \u003d domain, logits \u003d logits)\n\ndef G_loss(fake_D_src, target_D_cls, target_domain,input_image, reconstructed_image, lambda_cls,lambda_rec):\n  loss \u003d adverserial_loss(fake_D_src, real\u003dTrue) + lambda_cls * domain_cls_loss(target_domain, target_D_cls) + lambda_rec * reconstruction_loss(input_image, reconstructed_image)\n  return loss\n\ndef D_loss(real_D_src, fake_D_src, original_domain, original_D_cls, lambda_cls):\n  loss \u003d -1 * (adverserial_loss(real_D_src, real\u003dTrue) + adverserial_loss(fake_D_src, real\u003dFalse)) + lambda_cls* domain_cls_loss(original_domain,original_D_cls)\n  return loss\n\ngenerator_optimizer \u003d tf.train.AdamOptimizer(1e-4)\ndiscriminator_optimizer \u003d tf.train.AdamOptimizer(1e-4)\n\ndef train_step(input_image, original_domain, target_domain):\n  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        \n    # generator + discriminator combined\n    fake_image \u003d generator(input_image, target_domain)  # step(b)\n    fake_D_src, target_D_cls \u003d discriminator(fake_image)  # step(d) # 우선 fake image를 넣어서 보조 classification을 학습\n    reconstructed_image \u003d generator(fake_image, original_domain) # step(c)\n\n    # discriminator\n    real_D_src, original_D_cls \u003d discriminator(input_image) #step(a) \n    fake_D_src, fake_D_cls \u003d discriminator(fake_image) #step(a) \n    \n    generator_loss \u003d G_loss(fake_D_src, target_D_cls, target_domain,input_image, reconstructed_image, lambda_cls,lambda_rec)\n    discriminator_loss \u003d D_loss(real_D_src, fake_D_src, original_domain, original_D_cls, lambda_cls)\n    \n    gradients_of_generator \u003d gen_tape.gradient(generator_loss, generator.trainable_variables)\n    gradients_of_discriminator \u003d disc_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n    print()\n\ndef train(train_dataset, epochs):\n  for epoch in range(epochs):\n    start \u003d time.time()\n\n    for input_image, original_domain in train_dataset:\n            \n      target_domain \u003d random_target_domain_generation()\n      train_step(input_image, original_domain, target_domain)\n          \n\n\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf2",
      "language": "python",
      "name": "tf2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}