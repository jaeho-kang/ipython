{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. set cuda disabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import TensorFlow >= 1.10 and enable eager execution\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_zip = tf.keras.utils.get_file('facades.tar.gz',\n",
    "                                      cache_subdir=os.path.abspath('.'),\n",
    "                                      origin='https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz', \n",
    "                                      extract=True)\n",
    "\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'facades/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 400\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(image_file, is_train):\n",
    "  image = tf.read_file(image_file)\n",
    "  image = tf.image.decode_jpeg(image)\n",
    "\n",
    "  w = tf.shape(image)[1]\n",
    "\n",
    "  w = w // 2\n",
    "  real_image = image[:, :w, :]\n",
    "  input_image = image[:, w:, :]\n",
    "\n",
    "  input_image = tf.cast(input_image, tf.float32)\n",
    "  real_image = tf.cast(real_image, tf.float32)\n",
    "\n",
    "  if is_train:\n",
    "    # random jittering\n",
    "    \n",
    "    # resizing to 286 x 286 x 3\n",
    "    input_image = tf.image.resize_images(input_image, [286, 286], \n",
    "                                        align_corners=True, \n",
    "                                        method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = tf.image.resize_images(real_image, [286, 286], \n",
    "                                        align_corners=True, \n",
    "                                        method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
    "    cropped_image = tf.random_crop(stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "    input_image, real_image = cropped_image[0], cropped_image[1]\n",
    "\n",
    "    if np.random.random() > 0.5:\n",
    "      # random mirroring\n",
    "      input_image = tf.image.flip_left_right(input_image)\n",
    "      real_image = tf.image.flip_left_right(real_image)\n",
    "  else:\n",
    "    input_image = tf.image.resize_images(input_image, size=[IMG_HEIGHT, IMG_WIDTH], \n",
    "                                         align_corners=True, method=2)\n",
    "    real_image = tf.image.resize_images(real_image, size=[IMG_HEIGHT, IMG_WIDTH], \n",
    "                                        align_corners=True, method=2)\n",
    "  \n",
    "  # normalizing the images to [-1, 1]\n",
    "  input_image = (input_image / 127.5) - 1\n",
    "  real_image = (real_image / 127.5) - 1\n",
    "\n",
    "  return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.list_files(PATH+'train/*.jpg')\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.map(lambda x: load_image(x, True))\n",
    "train_dataset = train_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.list_files(PATH+'test/*.jpg')\n",
    "test_dataset = test_dataset.map(lambda x: load_image(x, False))\n",
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((?, 256, 256, ?), (?, 256, 256, ?)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, ReLU, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "    #encoder\n",
    "    def encoder(self, x):\n",
    "        conv1 = Conv2D(64, [4,4] , padding='same', activation=ReLU())(x)\n",
    "        conv2 = Conv2D(128, [4,4], padding='same', activation=ReLU())(conv1)\n",
    "        bn = BatchNormalization()(conv2)\n",
    "        return bn\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        deconv1 = Conv2DTranspose(128, [4,4], padding='same', activation=ReLU())(x)\n",
    "        deconv2 = Conv2DTranspose( 64, [4,4], padding='same', activation=ReLU())(deconv1)\n",
    "        return deconv2\n",
    "    \n",
    "    def call(self,x):\n",
    "        print('call called')\n",
    "        print(x.shape)\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call called\n",
      "(4, 256, 256, 3)\n",
      "(4, 256, 256, 64)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random_normal([4,256,256,3])\n",
    "g = Generator()\n",
    "fake_image = g(x)\n",
    "print(fake_image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-11-b03cb7cc1b68>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-b03cb7cc1b68>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    def __call__(self, x):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "    def discriminator(self, x):\n",
    "        \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
